{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Training on MNIST Data Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROARMarketingConcepts/Recurrent-Neural-Network-Examples/blob/master/RNN_Training_on_MNIST_Data_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M-ZjSNrZT_xe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Recall the MNIST dataset is 70,000 hand-written digits."
      ]
    },
    {
      "metadata": {
        "id": "QxEfdHVh0Seo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"rnn\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBwacY1G0b_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-_HAwQzSyEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: we will use `tf.layers.dense()` instead of `tensorflow.contrib.layers.fully_connected()`. The `dense()` function is almost identical to the `fully_connected()` function. The main relevant differences are:\n",
        "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
        "* the default `activation` is now `None` rather than `tf.nn.relu`."
      ]
    },
    {
      "metadata": {
        "id": "XETN0893YNq2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First, let's train a single layer RNN with 150 neurons..."
      ]
    },
    {
      "metadata": {
        "id": "p-BzMOO6FqqY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_steps = 28\n",
        "n_inputs = 28\n",
        "n_neurons = 150\n",
        "n_outputs = 10   # predict digits 0-9\n",
        "\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPteEE3pGBTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
        "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
        "\n",
        "logits = tf.layers.dense(states, n_outputs)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44OOM1XYG3mQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EopHf88hG9HU",
        "colab_type": "code",
        "outputId": "4fdb80bf-e1c7-4e91-caa5-38cf54965917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
        "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))  # shape of (10000, 28, 28)\n",
        "y_test = mnist.test.labels                                   # shape of (10000,)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-68c84a69842e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RyYDUWP_HDs2",
        "colab_type": "code",
        "outputId": "3351cac6-a489-41d1-b4ad-a73c1ced1ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "            \n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        \n",
        "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.93333334 Test accuracy: 0.9311\n",
            "1 Train accuracy: 0.96666664 Test accuracy: 0.9522\n",
            "2 Train accuracy: 0.97333336 Test accuracy: 0.9579\n",
            "3 Train accuracy: 0.96666664 Test accuracy: 0.9625\n",
            "4 Train accuracy: 0.97333336 Test accuracy: 0.9645\n",
            "5 Train accuracy: 0.9866667 Test accuracy: 0.9679\n",
            "6 Train accuracy: 0.96 Test accuracy: 0.9626\n",
            "7 Train accuracy: 0.98 Test accuracy: 0.9718\n",
            "8 Train accuracy: 0.94666666 Test accuracy: 0.9692\n",
            "9 Train accuracy: 0.98 Test accuracy: 0.9714\n",
            "10 Train accuracy: 0.9866667 Test accuracy: 0.9758\n",
            "11 Train accuracy: 0.96 Test accuracy: 0.9745\n",
            "12 Train accuracy: 0.98 Test accuracy: 0.972\n",
            "13 Train accuracy: 0.9866667 Test accuracy: 0.9737\n",
            "14 Train accuracy: 0.98 Test accuracy: 0.9709\n",
            "15 Train accuracy: 1.0 Test accuracy: 0.9752\n",
            "16 Train accuracy: 0.99333334 Test accuracy: 0.9773\n",
            "17 Train accuracy: 0.9866667 Test accuracy: 0.9733\n",
            "18 Train accuracy: 0.98 Test accuracy: 0.9663\n",
            "19 Train accuracy: 0.9866667 Test accuracy: 0.979\n",
            "20 Train accuracy: 0.97333336 Test accuracy: 0.9748\n",
            "21 Train accuracy: 0.96 Test accuracy: 0.9741\n",
            "22 Train accuracy: 0.97333336 Test accuracy: 0.9742\n",
            "23 Train accuracy: 0.98 Test accuracy: 0.9765\n",
            "24 Train accuracy: 0.9866667 Test accuracy: 0.9703\n",
            "25 Train accuracy: 1.0 Test accuracy: 0.9806\n",
            "26 Train accuracy: 0.9866667 Test accuracy: 0.9793\n",
            "27 Train accuracy: 0.9866667 Test accuracy: 0.9768\n",
            "28 Train accuracy: 0.98 Test accuracy: 0.9743\n",
            "29 Train accuracy: 1.0 Test accuracy: 0.9782\n",
            "30 Train accuracy: 0.99333334 Test accuracy: 0.9801\n",
            "31 Train accuracy: 0.9866667 Test accuracy: 0.9793\n",
            "32 Train accuracy: 0.98 Test accuracy: 0.9782\n",
            "33 Train accuracy: 1.0 Test accuracy: 0.9778\n",
            "34 Train accuracy: 0.99333334 Test accuracy: 0.9734\n",
            "35 Train accuracy: 1.0 Test accuracy: 0.9751\n",
            "36 Train accuracy: 1.0 Test accuracy: 0.9766\n",
            "37 Train accuracy: 0.99333334 Test accuracy: 0.9766\n",
            "38 Train accuracy: 0.9866667 Test accuracy: 0.9778\n",
            "39 Train accuracy: 1.0 Test accuracy: 0.9801\n",
            "40 Train accuracy: 0.99333334 Test accuracy: 0.9782\n",
            "41 Train accuracy: 0.9866667 Test accuracy: 0.9754\n",
            "42 Train accuracy: 0.99333334 Test accuracy: 0.9741\n",
            "43 Train accuracy: 0.9866667 Test accuracy: 0.9792\n",
            "44 Train accuracy: 0.97333336 Test accuracy: 0.9759\n",
            "45 Train accuracy: 0.99333334 Test accuracy: 0.98\n",
            "46 Train accuracy: 0.9866667 Test accuracy: 0.9806\n",
            "47 Train accuracy: 0.99333334 Test accuracy: 0.9786\n",
            "48 Train accuracy: 0.9866667 Test accuracy: 0.9786\n",
            "49 Train accuracy: 1.0 Test accuracy: 0.9808\n",
            "50 Train accuracy: 1.0 Test accuracy: 0.9771\n",
            "51 Train accuracy: 0.99333334 Test accuracy: 0.9787\n",
            "52 Train accuracy: 0.9866667 Test accuracy: 0.9755\n",
            "53 Train accuracy: 0.99333334 Test accuracy: 0.9798\n",
            "54 Train accuracy: 1.0 Test accuracy: 0.9798\n",
            "55 Train accuracy: 0.9866667 Test accuracy: 0.9758\n",
            "56 Train accuracy: 1.0 Test accuracy: 0.9799\n",
            "57 Train accuracy: 0.9866667 Test accuracy: 0.9777\n",
            "58 Train accuracy: 0.9866667 Test accuracy: 0.9778\n",
            "59 Train accuracy: 1.0 Test accuracy: 0.9776\n",
            "60 Train accuracy: 1.0 Test accuracy: 0.981\n",
            "61 Train accuracy: 1.0 Test accuracy: 0.9795\n",
            "62 Train accuracy: 0.9866667 Test accuracy: 0.9697\n",
            "63 Train accuracy: 1.0 Test accuracy: 0.9806\n",
            "64 Train accuracy: 0.99333334 Test accuracy: 0.9786\n",
            "65 Train accuracy: 1.0 Test accuracy: 0.9815\n",
            "66 Train accuracy: 1.0 Test accuracy: 0.9758\n",
            "67 Train accuracy: 0.99333334 Test accuracy: 0.9784\n",
            "68 Train accuracy: 1.0 Test accuracy: 0.9802\n",
            "69 Train accuracy: 0.99333334 Test accuracy: 0.9775\n",
            "70 Train accuracy: 0.98 Test accuracy: 0.9803\n",
            "71 Train accuracy: 0.99333334 Test accuracy: 0.9807\n",
            "72 Train accuracy: 0.99333334 Test accuracy: 0.9792\n",
            "73 Train accuracy: 1.0 Test accuracy: 0.9814\n",
            "74 Train accuracy: 0.98 Test accuracy: 0.9759\n",
            "75 Train accuracy: 0.98 Test accuracy: 0.9767\n",
            "76 Train accuracy: 0.9866667 Test accuracy: 0.9811\n",
            "77 Train accuracy: 0.9866667 Test accuracy: 0.9744\n",
            "78 Train accuracy: 0.99333334 Test accuracy: 0.9774\n",
            "79 Train accuracy: 0.99333334 Test accuracy: 0.9802\n",
            "80 Train accuracy: 0.9866667 Test accuracy: 0.9802\n",
            "81 Train accuracy: 0.9866667 Test accuracy: 0.9744\n",
            "82 Train accuracy: 0.96666664 Test accuracy: 0.9753\n",
            "83 Train accuracy: 1.0 Test accuracy: 0.9817\n",
            "84 Train accuracy: 1.0 Test accuracy: 0.9825\n",
            "85 Train accuracy: 0.9866667 Test accuracy: 0.98\n",
            "86 Train accuracy: 1.0 Test accuracy: 0.9764\n",
            "87 Train accuracy: 0.98 Test accuracy: 0.9788\n",
            "88 Train accuracy: 1.0 Test accuracy: 0.9778\n",
            "89 Train accuracy: 1.0 Test accuracy: 0.9786\n",
            "90 Train accuracy: 0.99333334 Test accuracy: 0.9775\n",
            "91 Train accuracy: 0.9866667 Test accuracy: 0.976\n",
            "92 Train accuracy: 0.9866667 Test accuracy: 0.9815\n",
            "93 Train accuracy: 0.99333334 Test accuracy: 0.9789\n",
            "94 Train accuracy: 0.98 Test accuracy: 0.9797\n",
            "95 Train accuracy: 0.99333334 Test accuracy: 0.9807\n",
            "96 Train accuracy: 0.99333334 Test accuracy: 0.9801\n",
            "97 Train accuracy: 0.99333334 Test accuracy: 0.9761\n",
            "98 Train accuracy: 0.96666664 Test accuracy: 0.9717\n",
            "99 Train accuracy: 0.99333334 Test accuracy: 0.9807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m4xxeatMk0eg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We get over 98% accuracy on the test set...not bad!!  We could improve this with hyperparameter optimization and some dropout."
      ]
    },
    {
      "metadata": {
        "id": "k6iHidNAb9jS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's now train a multi-layer RNN for the MNIST dataset..."
      ]
    },
    {
      "metadata": {
        "id": "tOpERLH1i5XY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_steps = 28\n",
        "n_inputs = 28\n",
        "n_outputs = 10\n",
        "n_neurons = 100\n",
        "n_layers = 3\n",
        "\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Z9-bmubjUgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons,activation=tf.nn.relu) for layer in range(n_layers)]\n",
        "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
        "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BkPS7XWmjJRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "states_concat = tf.concat(axis=1, values=states)\n",
        "logits = tf.layers.dense(states_concat, n_outputs)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TvVKxBrok4WD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wAH_N5STk-M0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3037a0da-e9f5-49e8-8964-2a4c071ba67c"
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "batch_size = 150\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.96 Test accuracy: 0.9367\n",
            "1 Train accuracy: 0.9866667 Test accuracy: 0.963\n",
            "2 Train accuracy: 0.9533333 Test accuracy: 0.9639\n",
            "3 Train accuracy: 0.96666664 Test accuracy: 0.9732\n",
            "4 Train accuracy: 0.98 Test accuracy: 0.9748\n",
            "5 Train accuracy: 0.96666664 Test accuracy: 0.9756\n",
            "6 Train accuracy: 0.98 Test accuracy: 0.9803\n",
            "7 Train accuracy: 0.9866667 Test accuracy: 0.9802\n",
            "8 Train accuracy: 0.99333334 Test accuracy: 0.982\n",
            "9 Train accuracy: 0.99333334 Test accuracy: 0.9829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ECd8tq4wmiYv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Again, we achieve over 98% accuracy on the test set!!"
      ]
    }
  ]
}